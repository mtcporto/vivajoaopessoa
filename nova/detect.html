<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detecção de Objetos</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        #video {
            display: none;
        }
        #canvas {
            width: 100%; /* Largura responsiva */
            max-width: 640px; /* Largura máxima */
            height: auto; /* Altura automática para manter a proporção */
            border: 1px solid #ddd;
            border-radius: 8px;
            display: block; /* Evita espaços extras */
            margin: 0 auto; /* Centraliza o canvas */
        }
        .container { /* Para o container */
            max-width: 640px;
        }
    </style>
</head>
<body class="container mt-5">
    <h1 class="text-center">Detecção de Objetos com Webcam</h1>
    <div class="text-center">
        <canvas id="canvas"></canvas>
        <video id="video" autoplay playsinline></video> <button id="switchCamera" class="btn btn-primary mt-2">Trocar Câmera</button>
    </div>
    <script>
    // Mapeamento de traduções (inglês -> português)
    const translations = {
      "person": "pessoa",
      "chair": "cadeira",
      "table": "mesa",
      "bottle": "garrafa",
      "cup": "copo",
      "tv": "televisão",
      "laptop": "notebook",
      "cell phone": "celular",
      // Adicione mais traduções conforme necessário
    };

        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        const switchCameraButton = document.getElementById('switchCamera');

        let currentStream = null;
        let facingMode = "user"; // Inicializa com a câmera frontal

        async function startCamera() {
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: facingMode } });
                video.srcObject = stream;
                currentStream = stream;
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                };
            } catch (err) {
                console.error("Erro ao acessar a webcam: ", err);
            }
        }

        switchCameraButton.addEventListener('click', () => {
            facingMode = facingMode === "user" ? "environment" : "user";
            startCamera();
        });

        cocoSsd.load().then((model) => {
            console.log("Modelo carregado!");
            startCamera().then(() => { // Inicia a câmera após o carregamento do modelo
                video.addEventListener('loadeddata', async () => {
                    setInterval(async () => {
                        context.drawImage(video, 0, 0, canvas.width, canvas.height); // Desenha normalmente
                        const predictions = await model.detect(video);

                        predictions.forEach((prediction) => {
                            const [x, y, width, height] = prediction.bbox;
                            const label = translations[prediction.class] || prediction.class;

                            context.strokeStyle = "red";
                            context.lineWidth = 2;
                            context.strokeRect(x, y, width, height); // Desenha o retângulo normalmente

                            context.fillStyle = "red";
                            context.font = "16px Arial";
                            context.fillText(label, x, y > 10 ? y - 5 : y + 15);
                        });
                    }, 100);
                });
            });
        });
    </script>
</body>
</html>
